---
title: 'Tipologia i cicle de vida de les dades - Pr√†ctica 2 - Neteja i modelatge de dades'
author: "V√≠ctor Olivera Begue, Guillem Romeu Graells"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    number_sections: true
    toc_depth: 2
  html_document:
    toc: true
    number_sections: true
---

# Carregar llibreries i dades

```{r setup, message=FALSE, warning=FALSE}
# Carreguem les llibreries principals
library(tidyverse)    # manipulaci√≥
library(naniar)       # visual missings
library(caret)        # partici√≥ i nearZeroVar
library(VIM)          # kNN imputaci√≥
library(randomForest) # random forest
library(cluster)      # dist, hclust
library(factoextra)   # fviz_cluster
library(rstatix)      # tests estad√≠stics
library(stats)        # chisq.test
set.seed(123)

# Llegim el CSV original, indicant que "?" sigui NA
adult <- read_csv("adult.csv", na = "?",   skip = 1,
                  col_names = c("age","workclass","fnlwgt","education","educational_num",
                                "marital_status","occupation","relationship","race","sex",
                                "capital_gain","capital_loss","hours_per_week","native_country",
                                "income"))
```

# Descripci√≥ del dataset

Tot i que a la Pr√†ctica 1 vam crear un dataset propi mitjan√ßant web scraping, en aquesta pr√†ctica hem optat per treballar amb un nou conjunt de dades: el *Adult Income Dataset* del UCI Machine Learning Repository. Aquesta decisi√≥ es justifica perqu√® el dataset anterior no complia les condicions requerides per aquesta pr√†ctica, ja que:

- No contenia una variable objectiu bin√†ria adequada.
- No hi havia prou volum ni varietat de dades categ√≤riques i num√®riques.
- No era suficientment ric en valors perduts ni outliers per aplicar t√®cniques de neteja avan√ßades.

Per aix√≤, hem decidit utilitzar un dataset p√∫blic i ben establert que ens permet aplicar totes les fases del cicle de vida de les dades amb profunditat i justificaci√≥ t√®cnica.

El dataset **Adult Income** (‚ÄúCensus Income‚Äù) de l‚ÄôUCI √©s un dels referents cl√†ssics en problemes de classificaci√≥ bin√†ria, ja que permet predir si el salari anual d‚Äôun individu supera els 50 000 \$ basant-se en caracter√≠stiques sociodemogr√†fiques i laborals obtingudes del cens de 1994. Aquesta relaci√≥ entre atributs personals (com edat, sexe, educaci√≥) i l‚Äôingr√©s serveix com a punt de partida per a models de decisions en recursos humans, sistemes de cr√®dit i pol√≠tiques p√∫bliques de redistribuci√≥, a m√©s de ser √†mpliament utilitzat en la recerca per validar noves t√®cniques de machine learning i d‚Äôan√†lisi de discriminaci√≥ salarial.

El conjunt consta de **48 842 inst√†ncies** i **14 variables** originals m√©s la variable objectiu (>50K / ‚â§50K), i presenta tant **atributs num√®rics** (p. ex., *age*, *fnlwgt*, *capital-gain*, *hours-per-week*) com **categ√≤rics** (p. ex., *workclass*, *education*, *marital-status*, *occupation*, *native-country*) A m√©s, inclou valors mancants en algunes categories (p. ex., *workclass*, *occupation*), fet que requereix t√®cniques d‚Äôimputaci√≥ i garanteix pr√†ctica en la gesti√≥ de dades reals.

Disposar de variables heterog√®nies i reals permet desenvolupar models predictius robustos (com regressi√≥ log√≠stica, arbres de decisi√≥ o gradient boosting) i entendre la influ√®ncia relativa de cada factor en la probabilitat de guanyar m√©s de 50 000 \$/any. Per exemple, l‚Äôeducaci√≥ i les hores setmanals solen ser predictors forts, mentre que variables demogr√†fiques com el g√®nere o la nacionalitat ajuden a detectar possibles biaixos i dissenyar pol√≠tiques m√©s equitatives. Aquestes capacitats converteixen l‚ÄôAdult Income en un exercici ideal per a l‚Äôaplicaci√≥ de totes les etapes: neteja, exploraci√≥, modelatge i interpretaci√≥ de resultats.


# Integraci√≥ i selecci√≥ inicial

### Definir variables numeriques i categoriques

```{r}
# Definim manualment quines volem num√®riques i quines factors:

num_vars <- c(
  "age",
  "fnlwgt",
  "educational_num",
  "capital_gain",
  "capital_loss",
  "hours_per_week"
)

fac_vars <- setdiff(
  names(adult),
  num_vars
)

# Excloem d‚Äôentre els factor tamb√© la columna income_bin si ja existeix,
# i assegurem income com a factor abans de crear income_bin:
fac_vars <- setdiff(fac_vars, "income_bin")

# Ara fem la conversi√≥:
adult <- adult %>%
  # convertir a num√®ric les que volem num√®riques
  mutate(across(all_of(num_vars), as.numeric)) %>%
  # convertir a factor la resta de caracter√≠stiques
  mutate(across(all_of(fac_vars), as.factor)) %>%
  # crear income_bin basat en income
  mutate(
    income     = as.factor(income),
    income_bin = factor(if_else(income == ">50K", "high", "low"),
                        levels = c("low","high"))
  )

# Verifiquem tipus
glimpse(adult)

```

## Resum estad√≠stic i detecci√≥ de missings

```{r }
# Resum descriptiu
summary(adult)

# Comptar missings
adult %>%
  summarise_all(~ sum(is.na(.))) %>%
  pivot_longer(everything(), names_to="var", values_to="n_miss")

# Proporci√≥ de missings
adult %>%
  summarise_all(~ mean(is.na(.))) %>%
  pivot_longer(everything(), names_to="var", values_to="pct_miss")

# Mapa visual de missings
vis_miss(adult) + 
  labs(title="Patr√≥ de missings al dataset")
```

## Creaci√≥ de variables noves

```{r}
# Discretitzaci√≥ d'edat
adult2 <- adult %>%
  # net_capital = guanys - p√®rdues
  mutate(net_capital = capital_gain - capital_loss) %>%
  mutate(age_group = cut(age,
                         breaks=c(15,20,30,40,50,60,70,80,90,Inf),
                         labels=c("15-19","20-29","30-39","40-49","50-59",
                                  "60-69","70-79","80-89","90+"),
                         right=FALSE))
```

## Variables irrelevants i cardinalitat

```{r var-selection}
# Variables amb gaireb√© zero vari√†ncia
nzv <- nearZeroVar(adult2, saveMetrics=TRUE)
rownames(nzv)[nzv$nzv]

# Agrupar pa√Øsos amb <1% en "Other"
table(adult2$native_country)
adult3 <- adult2 %>%
  mutate(native_country = fct_lump(native_country, prop=0.01, other_level="Other"))

table(adult3$native_country)

```

## Distribuci√≥ de classes i sampling

```{r}
# Distribuci√≥ original de sex
adult3 %>%
  count(sex) %>%
  mutate(pct = n/sum(n)*100)

# Oversampling amb ROSE per equilibrar 50/50
library(ROSE)
adult4 <- ovun.sample(sex ~ ., data=adult3, method="both", p=0.5, N=nrow(adult3))$data

# Verificar nova distribuci√≥
adult4 %>%
  count(sex) %>%
  mutate(pct = n/sum(n)*100)
```
Fem un oversample per igualar els casos de homes i dones 

# Neteja de dades

## Imputaci√≥ kNN en workclass i occupation

```{r}
table(adult4$occupation)
adult_imp <- kNN(adult4,
                 variable=c("workclass","occupation"),
                 k=5, imp_var=FALSE)
# Perque no despareixin els outliers
adult_fac <- adult_imp
```
## Detecci√≥ d‚Äôoutliers

### Boxplots univariants

```{r}
num_vars <- adult_fac %>% select(where(is.numeric)) %>% names()
for(v in num_vars){
  v_esc <- paste0("`",v,"`")
  p <- ggplot(adult_fac, aes_string(x="factor(1)", y=v_esc)) +
    geom_boxplot(outlier.colour="red", outlier.alpha=0.4) +
    labs(title=paste("Boxplot de",v), x=NULL, y=v) +
    theme_minimal() +
    theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
  print(p)
}
```

### Cook‚Äôs distance en model log√≠stic

```{r}
# 1) Recalculem la dist√†ncia de Cook
adult_fac <- adult_fac %>%
  mutate(income_bin = if_else(income == ">50K", 1, 0))

glm_mod2 <- glm(income_bin ~ age + hours_per_week + educational_num,
                data   = adult_fac,
                family = binomial)

cooksd <- cooks.distance(glm_mod2)

# 2) Definim el llindar d‚Äôinflu√®ncia
n <- nrow(adult_fac)
p <- length(coef(glm_mod2))
threshold <- 4 / (n - p - 1)

# 3) Identifiquem i eliminem les observacions per sobre del llindar
influential_obs <- which(cooksd > threshold)
length(influential_obs)  # nombre de punts cr√≠tics

adult_noinflu <- adult_fac[-influential_obs, ]

# 4) Replot de la dist√†ncia de Cook amb el llindar marcat
plot(cooksd, pch="*", cex=0.5,
     main = "Cook's distance (log√≠stic) amb llindar")
abline(h = threshold, col = "red", lwd = 2)
text(x = influential_obs, y = cooksd[influential_obs],
     labels = influential_obs, pos = 3, cex = 0.7)

# 5) Veiem com han quedat les dades sense els outliers influents
cat("Observacions eliminades:", length(influential_obs), "\n")
cat("Nova mida de dataset:", nrow(adult_noinflu), "\n")

```

# An√†lisi de les dades

```{r setup2, message=FALSE, warning=FALSE}
# Carreguem llibreries i configurem semilla
library(tidyverse)
library(caret)         # createDataPartition, confusionMatrix
library(randomForest)  # random forest (no supervisat opcional)
library(pROC)          # roc, auc
library(cluster)       # dist, silhouette
library(factoextra)    # fviz_cluster
library(rstatix)       # tests estad√≠stics
library(stats)         # chisq.test
set.seed(123)
```

## Preparaci√≥ de train/test
```{r}
# Partim de `adult_noinflu` amb income_bin ja en factor("low","high")
# Exemple: adult_noinflu <- adult_noinflu %>% mutate(income_bin = factor(if_else(income==">50K","high","low"), levels=c("low","high")))

idx   <- createDataPartition(adult_noinflu$income_bin, p = 0.7, list = FALSE)
train <- adult_noinflu[idx, ]
test  <- adult_noinflu[-idx, ]

```

## Ajust i predicci√≥ amb regressi√≥ log√≠stica
```{r}
# Ajust sobre TRAIN
glm_mod <- glm(
  income_bin ~ age + hours_per_week + educational_num + net_capital,
  data   = train,
  family = binomial
)

# Prediccions sobre TEST
# Ajustat perqu√® pred_test √©s character i no t√© els mateixos nivells que test$income_bin.
probs_test <- predict(glm_mod, test, type = "response")
pred_test <- factor(
  if_else(probs_test > 0.5, "high", "low"),
  levels = c("low", "high")
)
test$income_bin <- factor(test$income_bin, levels = c("low", "high"))

# Matriu de confusi√≥ i Accuracy
conf_glm <- confusionMatrix(pred_test, test$income_bin)
print(conf_glm$table)
cat("Accuracy (glm):", round(conf_glm$overall["Accuracy"], 3), "\n")

# AUC
# Comprovem si el test cont√© les dues classes
if (length(unique(test$income_bin)) == 2) {
  roc_glm <- roc(response = test$income_bin,
                 predictor = probs_test,
                 levels = c("low", "high"))
  cat("AUC (glm):", round(auc(roc_glm), 3), "\n")
} else {
  cat("No es pot calcular l'AUC: nom√©s hi ha una classe a test$income_bin\n")
}

```
## Model no supervisat amb predicci√≥ i m√®triques: PAM + mapatge a classes

```{r unsup-pam-with-pred, message=FALSE, warning=FALSE}
library(cluster)
library(factoextra)
library(caret)

# 5.3.1 Normalitzaci√≥ Min‚ÄìMax de dues variables en TRAIN i TEST
norm_vars <- c("age", "hours_per_week")

train_norm <- train %>%
  select(all_of(norm_vars)) %>%
  drop_na() %>%
  mutate(across(everything(),
                ~ (. - min(.)) / (max(.) - min(.))))

test_norm <- test %>%
  select(all_of(norm_vars)) %>%
  drop_na() %>%
  mutate(across(everything(),
                ~ (. - min(train_norm[[cur_column()]])) /
                  (max(train_norm[[cur_column()]]) - min(train_norm[[cur_column()]]))))

# 5.3.2 Ajustem PAM amb k = 2 sobre TRAIN
pam_mod <- pam(train_norm, k = 2)

# 5.3.3 Mapatge de clusters a classes reals en TRAIN
train_clusters <- pam_mod$clustering
cluster_to_class <- tapply(train$income_bin, train_clusters,
                           function(x) names(sort(table(x), decreasing=TRUE))[1])
# Ara cluster_to_class[["1"]] √©s la classe majorit√†ria del cluster 1, etc.

# 5.3.4 Assignaci√≥ de TEST a cl√∫sters (dist√†ncia al medoid m√©s proper)
medoids <- pam_mod$medoids
dists_test <- sapply(1:2, function(k) {
  rowSums((as.matrix(test_norm) - medoids[k, ])^2)
})
test_clusters <- apply(dists_test, 1, which.min)

# 5.3.5 Predicci√≥ de classes a TEST a partir del mapatge
pred_pam_class <- factor(cluster_to_class[test_clusters], levels = c("low","high"))

# 5.3.6 M√®triques d‚Äôajust: Matriu de confusi√≥ i accuracy
conf_pam <- confusionMatrix(pred_pam_class, test$income_bin)
print(conf_pam$table)
cat("Accuracy (PAM-based):", round(conf_pam$overall["Accuracy"], 3), "\n")

# 5.3.7 Silhouette width mitjana sobre TRAIN
avg_sil_pam <- pam_mod$silinfo$avg.width
cat("Silhouette width mitjana (TRAIN):", round(avg_sil_pam, 3), "\n")

# 5.3.8 Visualitzaci√≥ del model sobre TRAIN
fviz_cluster(pam_mod,
             geom         = "point",
             ellipse.type = "convex",
             ggtheme      = theme_minimal()) +
  labs(title = "PAM (k = 2) sobre TRAIN (age & hours_per_week)")
``` 


**Explicaci√≥ del flux:**

1. **Normalitzaci√≥**: escales Min‚ÄìMax per `age` i `hours_per_week` en train i test (usant rang de train per al test).  
2. **Entrenament PAM**: creem 2 cl√∫sters sobre el train.  
3. **Mapatge a classes**: assignem a cada cl√∫ster la classe (`low`/`high`) m√©s freq√ºent en train.  
4. **Predicci√≥ en test**: calculem la dist√†ncia quadr√†tica de cada punt de test als medoids i triem el cl√∫ster m√©s proper.  
5. **M√®triques**: constru√Øm la matriu de confusi√≥ comparant classes predites vs reals i calculem accuracy.  
6. **Silueta**: imprimim la mitjana de l‚Äô√≠ndex de silueta sobre el train per avaluar qualitat de clustering.  
7. **Plot**: representem els cl√∫sters de train amb el¬∑lipse convexa sobre les dues variables.


## Proves d‚Äôhip√≤tesis amb comprovaci√≥ d‚Äôassumpcions

```{r}
library(rstatix)
library(stats)
```

**Nota:** partim del conjunt `train` amb la variable `income_bin` ja transformada a factor amb els nivells `"low"` i `"high"`.


## Test A: hours_per_week ~ income_bin
```{r}
train <- train[1:4000,] # El test shapiro accepta m√†xim 5000 dades

# 1) Normalitat per grup
# Normalitat per grup (limitant a m√†xim 5000 observacions)
hours_low  <- train %>% filter(income_bin == "low") %>% pull(hours_per_week)
hours_high <- train %>% filter(income_bin == "high") %>% pull(hours_per_week)

hours_low  <- hours_low[1:min(5000, length(hours_low))]
hours_high <- hours_high[1:min(5000, length(hours_high))]

if (length(hours_low) >= 3 && length(hours_high) >= 3) {
  sh_low  <- shapiro_test(hours_low)
  sh_high <- shapiro_test(hours_high)
} else {
  cat("No es pot aplicar el test de Shapiro: mostra massa petita.\n")
  sh_low <- sh_high <- NULL
}

# 2) Homogene√Øtat de vari√†ncies
# Assegurem que income_bin √©s factor amb almenys dues categories
train$income_bin <- factor(train$income_bin, levels = c("low", "high"))

if (nlevels(droplevels(train$income_bin)) < 2) {
  cat("No es pot fer el test de Levene: nom√©s hi ha una categoria a income_bin.\n")
  lev <- NULL
} else {
  lev <- levene_test(hours_per_week ~ income_bin, data = train)
}


# 3) Selecci√≥ del test
# Selecci√≥ del test (si tenim resultats de Shapiro)
if (!is.null(sh_low) && !is.null(sh_high) && !is.null(lev) &&
    sh_low$p.value > 0.05 && sh_high$p.value > 0.05 && lev$p > 0.05)
 {
  test_hours <- t_test(hours_per_week ~ income_bin, data = train)
  cat("Usant t-test perqu√® es compleixen normalitat i homocedasticitat\n")
} else {
# Comprovaci√≥ de mida abans de fer Wilcoxon
if (nrow(train %>% drop_na(hours_per_week)) >= 10 &&
    length(unique(na.omit(train$income_bin))) == 2) {
  test_hours <- wilcox_test(hours_per_week ~ income_bin, data = train)
} else {
  cat("No es pot aplicar el test de Wilcoxon: no hi ha prou dades o classes.\n")
  test_hours <- NULL
}

  cat("Usant Wilcoxon perqu√® no es compleixen els requisits d‚Äôun t-test\n")
}

print(sh_low)
print(sh_high)
print(lev)
if (!is.null(test_hours)) print(test_hours)

```
El resultat del Wilcoxon comparant `hours_per_week` entre els dos grups (low vs. high) √©s:

* **W = 1 131 097**, **p < 2 √ó 10‚Åª¬π‚Å∂** (aprox. 1.49 √ó 10‚Åª‚Å∂‚Å¥)
* **n‚ÇÅ = 2 822** (low), **n‚ÇÇ = 1 178** (high)

Com que **p ‚â™ 0,05**, rebutgem l‚Äôhip√≤tesi nul¬∑la de distribucions iguals de `hours_per_week` entre els qui guanyen ‚â§ 50K i els que guanyen > 50K. Aix√≤ vol dir que hi ha una difer√®ncia **estad√≠sticament significativa** en nombre d‚Äôhores treballades setmanalment:

* Els ingressos m√©s alts s‚Äôassocien a **m√©s hores treballades** (la mediana del grup ‚Äúhigh‚Äù √©s superior a la del grup ‚Äúlow‚Äù).

Aix√≠, podem concloure que dedicar m√©s hores a la feina es relaciona amb una probabilitat m√©s alta de pert√†nyer al grup de > 50K.


# Representaci√≥ de distribucions despr√©s de la neteja

  Distribuci√≥ de valors per a variables categ√≤riques

```{r}
adult_fac %>%
  select(where(is.factor)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "valor") %>%
  count(variable, valor) %>%
  group_by(variable) %>%
  mutate(pct = round(n / sum(n) * 100, 2)) %>%
  arrange(variable, desc(n)) %>%
  print(n = 100)

# Estad√≠stiques descriptives de les variables num√®riques

adult_fac %>%
  select(where(is.numeric)) %>%
  summary()
```
# Codi

## Publicaci√≥ del codi

El codi desenvolupat per realitzar la neteja, transformaci√≥ i an√†lisi del conjunt de dades Adult Income es troba publicat al repositori GitHub seg√ºent:

üîó https://github.com/Guillemromeu/PAC2-TCVD-Victor-Guillem

L‚Äôarxiu principal √©s Pr√†ctica2.Rmd, ubicat dins la carpeta /codi, i cont√© tot el proc√©s anal√≠tic documentat: des de la c√†rrega de dades fins a les conclusions finals.

A m√©s, el repositori inclou els fitxers seg√ºents:

README.md: descripci√≥ general del projecte, estructura i instruccions d‚Äôexecuci√≥.

LICENSE: llic√®ncia del projecte per a √∫s educatiu.

/dades/adult.csv: dataset original extret del repositori UCI.

/dades/adult_net_final.csv: dataset final, netejat i imputat.

/informe/Mem√≤ria Pr√†ctica 2 V√≠ctor Olivera i Guillem Romeu.pdf: informe final generat a partir del codi.

# V√≠deo

Hem realitzat un v√≠deo de presentaci√≥ titulat ‚ÄúPr√†ctica 2 - V√≠deo explicatiu del projecte‚Äù, en el qual es mostren els aspectes m√©s rellevants de la pr√†ctica. L‚Äôenregistrament est√† disponible al seg√ºent enlla√ß:

https://drive.google.com/drive/folders/1uxO3c8djVWcA67RFlMv0UHM9rHlYm2yr

Durant el v√≠deo, ambd√≥s membres del grup participem activament, presentant:

‚Ä¢	El context i objectiu del projecte, basat en el Adult Income Dataset del UCI.

‚Ä¢	Les fases aplicades sobre el conjunt de dades: neteja, transformaci√≥, selecci√≥ i imputaci√≥.

‚Ä¢	L‚Äôaplicaci√≥ de models supervisats (regressi√≥ log√≠stica) i no supervisats (PAM).

‚Ä¢	L‚Äô√∫s de proves estad√≠stiques (Wilcoxon) amb comprovaci√≥ pr√®via d‚Äôassumpcions.

‚Ä¢	Les conclusions extretes, incloent-hi la interpretaci√≥ de resultats, limitacions i proposta de millora.

‚Ä¢	Els criteris √®tics considerats durant tot el proc√©s, treballant amb dades p√∫bliques i anonimitzades.

Per fer la presentaci√≥, hem seguit el gui√≥ facilitat pel model al punt anterior i hem intentat transmetre tant el valor anal√≠tic del projecte com el proc√©s t√®cnic dut a terme.

# Conclusions i propostes de millora

Aquest projecte ha perm√®s aplicar de manera pr√†ctica totes les fases del cicle de vida de les dades sobre un dataset real. El conjunt de dades *Adult Income* ha estat netejat, transformat i analitzat per predir si una persona guanya m√©s de 50.000‚ÄØ$ anuals, a partir de variables socioecon√≤miques i demogr√†fiques.

S‚Äôha tractat amb √®xit la pres√®ncia de valors perduts mitjan√ßant imputaci√≥ per kNN, s‚Äôhan unificat nivells amb baixa representaci√≥ i s‚Äôhan eliminat observacions influents amb dist√†ncia de Cook. El dataset net s‚Äôha usat per construir models supervisats (regressi√≥ log√≠stica) i no supervisats (clustering PAM), aix√≠ com per realitzar an√†lisis estad√≠stiques inferencials amb proves no param√®triques.

## Conclusions clau

- Variables com `educational_num`, `hours_per_week` i `net_capital` s√≥n les m√©s predictives per estimar els ingressos.
- El model de regressi√≥ log√≠stica ha obtingut una bona precisi√≥ (accuracy) i una AUC robusta.
- El clustering PAM, tot i no tenir acc√©s a la variable objectiu, ha pogut separar els grups amb una silueta mitjana acceptable.
- El test de Wilcoxon confirma que hi ha difer√®ncies significatives en les hores treballades entre persones amb ingressos baixos i alts.

## Limitacions

- El dataset √©s antic (1994) i pot no reflectir la realitat socioecon√≤mica actual.
- La variable `fnlwgt` no ha estat utilitzada; tot i que pot ser rellevant a nivell poblacional, no aportava valor directe al model.
- Tot i la imputaci√≥, algunes variables categ√≤riques poden conservar cert biaix.

## Propostes de millora

- Aplicar t√®cniques de validaci√≥ creuada (cross-validation) per avaluar millor el rendiment.
- Explorar altres models com random forests o XGBoost.
- Afegir variables derivades del pa√≠s d‚Äôorigen i estudiar el seu efecte.
- Fer una reflexi√≥ √®tica m√©s profunda sobre el biaix potencial de g√®nere o origen en els resultats.

# Taula de contribucions

**Contribucions i signatura**

- Investigaci√≥ pr√®via: G.R.G., V.O.B.
- Redacci√≥ de les respostes: G.R.G., V.O.B.
- Desenvolupament del codi: G.R.G., V.O.B.
- Participaci√≥ al v√≠deo: G.R.G., V.O.B.

> G.R.G. = Guillem Romeu Graells  
> V.O.B. = V√≠ctor Olivera Begue


# Exportaci√≥ del dataset final net

  Exportem el dataset netejat amb imputaci√≥ i transformacions finals
```{r}
if (interactive()) {
  write.csv(adult_fac, "adult_net_final.csv", row.names = FALSE)
}

```

